import asyncio
import logging
import requests
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.enums import ChatAction
from aiogram.types import ReplyKeyboardRemove

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_URL = "https://api.intelligence.io.solutions/api/v1"
TOKEN = "7839597384:AAFlm4v3qcudhJfiFfshz1HW6xpKhtqlV5g"
API_KEY = "io-v2-eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJvd25lciI6ImJlMjYwYjFhLWI0OWMtNDU2MC04ODZiLTMwYTBmMGFlNGZlNSIsImV4cCI6NDg5OTUwNTM1M30.Et777QmMZrknZ3dvxqiBClOrbkZV4SkUDfvOz21lys2hoyZs4oV_RFClBNyux3W03ikZFlwu2sKngFYqJU3b8Q"
MODELS = [
    'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8',
    'Qwen/QwQ-32B',
    'meta-llama/Llama-3.2-90B-Vision-Instruct',
    'deepseek-ai/DeepSeek-R1-Distill-Llama-70B',
    'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B',
    'meta-llama/Llama-3.3-70B-Instruct',
    'Qwen/Qwen2-VL-7B-Instruct',
    'databricks/dbrx-instruct',
    'mistralai/Ministral-8B-Instruct-2410',
    'netease-youdao/Confucius-01-14B',
    'nvidia/AceMath-7B-Instruct',
    'google/gemma-3-27b-it',
    'neuralmagic/Llama-3.1-Nemotron-70B-Instruct-HF-FP8-dynamic',
    'mistralai/Mistral-Large-Instruct-2411',
    'microsoft/phi-4',
    'SentientAGI/Dobby-Mini-Unhinged-Llama-3.1-8B',
    'watt-ai/watt-tool-70B',
    'bespokelabs/Bespoke-Stratos-32B',
    'NovaSky-AI/Sky-T1-32B-Preview',
    'tiiuae/Falcon3-10B-Instruct',
    'THUDM/glm-4-9b-chat',
    'Qwen/Qwen2.5-Coder-32B-Instruct',
    'CohereForAI/aya-expanse-326',
    'jinaai/ReaderLM-v2',
    'openbmb/MiniCPM3-4B',
    'Qwen/Qwen2.5-1.5B-Instruct',
    'ozone-ai/ox-1',
    'microsoft/Phi-3.5-mini-instruct',
    'ibm-granite/granite-3.1-8b-instruct'
]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
bot = Bot(token=TOKEN)
dp = Dispatcher()
current_model_index = 0

async def show_typing(chat_id: int):
    """–ê–∫—Ç–∏–≤–∞—Ü–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –Ω–∞–±–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞"""
    await bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    await asyncio.sleep(1.5)

def rotate_model():
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å"""
    global current_model_index
    current_model_index = (current_model_index + 1) % len(MODELS)
    logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –º–æ–¥–µ–ª—å: {MODELS[current_model_index]}")

async def send_response(message: types.Message, text: str):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —á–∞—Å—Ç–∏"""
    for chunk in [text[i:i+4090] for i in range(0, len(text), 4090)]:
        await message.answer(chunk, parse_mode=None)

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    await message.answer(
        "ü§ñ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.",
        reply_markup=ReplyKeyboardRemove()
    )

@dp.message(Command("models"))
async def cmd_models(message: types.Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    models_list = "\n".join([f"‚ñ´Ô∏è {model.split('/')[-1]}" for model in MODELS])
    await message.answer(
        f"üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ ({len(MODELS)}):\n{models_list}\n\n"
        f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {MODELS[current_model_index].split('/')[-1]}"
    )

@dp.message()
async def handle_message(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    global current_model_index

    # –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ø–µ—á–∞—Ç–∏
    await show_typing(message.chat.id)

    for attempt in range(len(MODELS)):
        current_model = MODELS[current_model_index]
        payload = {
            "model": current_model,
            "messages": [
                {
                    "role": "system",
                    "content": "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∫–æ–¥–æ–º –∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ."
                },
                {
                    "role": "user", 
                    "content": f"{message.text}\n\n–í–∫–ª—é—á–∏ –≤–µ—Å—å –∫–æ–¥ –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π."
                }
            ],
            "temperature": 0.2,
            "max_tokens": 4000
        }

        try:
            response = requests.post(
                f"{API_URL}/chat/completions",
                headers={"Authorization": f"Bearer {API_KEY}"},
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            data = response.json()

            if 'choices' in data and data['choices']:
                await send_response(message, data['choices'][0]['message']['content'])
                return

        except requests.exceptions.HTTPError as e:
            logger.error(f"–û—à–∏–±–∫–∞ {e.response.status_code} | –ú–æ–¥–µ–ª—å: {current_model}")
            rotate_model()
            await show_typing(message.chat.id)
            continue

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
            rotate_model()
            continue

    await message.answer("üö® –í—Å–µ –º–æ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

async def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
